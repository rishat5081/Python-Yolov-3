{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1597657169470",
   "display_name": "Python 3.8.3 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import numpy as np\n",
    "# import time\n",
    "# import sys\n",
    "# import os\n",
    "# net = cv2.dnn.readNet('yolov3.weights','yolov3.cfg')\n",
    "# classes = []\n",
    "# with open('coco.names','r') as f:\n",
    "#     classes = f.read().splitlines()\n",
    "# # printing the data which is loaded from the names file\n",
    "# #print(classes)\n",
    "# img = cv2.imread('image.jpg')\n",
    "# height, width, _ = img.shape\n",
    "# blob = cv2.dnn.blobFromImage(img, 1/255,  (416 , 416), (0,0,0) ,1,crop=False)\n",
    "\n",
    "# boxes = []\n",
    "# confidences = []\n",
    "# class_ids =[]\n",
    "# chairs=0\n",
    "# bottles =0 \n",
    "# diningtable = 0\n",
    "# # cv2.imshow('Image',img)\n",
    "# # cv2.waitKey(0)\n",
    "# # cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(\"image.shape:\", img.shape)\n",
    "# print(\"blob.shape:\", blob.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# net.setInput(blob)\n",
    "\n",
    "# ln = net.getLayerNames()\n",
    "# ln = [ln[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "# # feed forward (inference) and get the network output\n",
    "# # measure how much it took in seconds\n",
    "# start = time.perf_counter()\n",
    "# layer_outputs = net.forward(ln)\n",
    "# time_took = time.perf_counter() - start\n",
    "# print(f\"Time took: {time_took:.2f}s\")\n",
    "\n",
    "\n",
    "# # output_layer_names = net.getUnconnectedOutLayersNames()\n",
    "# # layerOutput = net.forward(output_layer_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for output in layerOutput:\n",
    "#     for detection in output:\n",
    "#         scores = detection[5:]\n",
    "#         class_id = np.argmax(scores)\n",
    "#         confidence = scores[class_id]\n",
    "#         if confidence > 0.5:\n",
    "#             center_x = int(detection[0]*width)\n",
    "#             center_y = int(detection[1]*height)\n",
    "#             w = int(detection[2]*width)\n",
    "#             h = int(detection[3]*height)\n",
    "\n",
    "\n",
    "#             x = int(center_x - w/2)\n",
    "#             y = int(center_y - h/2)\n",
    "\n",
    "#             boxes.append([x,y,w,h])\n",
    "#             confidences.append((float(confidence)))\n",
    "#             class_ids.append(class_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import cv2\n",
    "\n",
    "# # Load image\n",
    "# img = cv2.imread('image.jpg',1)\n",
    "\n",
    "# gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "# ret, thresh = cv2.threshold(gray, 80, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# contours, _ = cv2.findContours(thresh,\n",
    "#                                   cv2.RETR_TREE,\n",
    "#                                   cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "# x1, y1, w, h = cv2.boundingRect(contours[0])\n",
    "# x2, y2 = x1 + w, y1 + h\n",
    "# print((x1, y1), (x2, y2)) \n",
    "# cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "# cv2.imwrite('res.jpg', img)\n",
    "# cv2.imshow(\"Image\",img)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import numpy as np\n",
    "\n",
    "# import time\n",
    "# import sys\n",
    "# import os\n",
    "\n",
    "# CONFIDENCE = 0.5\n",
    "# SCORE_THRESHOLD = 0.5\n",
    "# IOU_THRESHOLD = 0.5\n",
    "\n",
    "# # the neural network configuration\n",
    "# config_path = \"yolov3.cfg\"\n",
    "# # the YOLO net weights file\n",
    "# weights_path = \"yolov3.weights\"\n",
    "\n",
    "# # loading all the class labels (objects)\n",
    "# labels = open(\"coco.names\").read().strip().split(\"\\n\")\n",
    "# # generating colors for each object for later plotting\n",
    "# colors = np.random.randint(0, 255, size=(len(labels), 3), dtype=\"uint8\")\n",
    "\n",
    "# # load the YOLO network\n",
    "# net = cv2.dnn.readNetFromDarknet(config_path, weights_path)\n",
    "\n",
    "# # path_name = \"images/city_scene.jpg\"\n",
    "# path_name = 'image.jpg'\n",
    "# image = cv2.imread(path_name)\n",
    "# file_name = os.path.basename(path_name)\n",
    "# filename, ext = file_name.split(\".\")\n",
    "\n",
    "# h, w = image.shape[:2]\n",
    "# # create 4D blob\n",
    "# blob = cv2.dnn.blobFromImage(image, 1/255.0, (416, 416), swapRB=True, crop=False)\n",
    "\n",
    "# # sets the blob as the input of the network\n",
    "# net.setInput(blob)\n",
    "\n",
    "# # get all the layer names\n",
    "# ln = net.getLayerNames()\n",
    "# ln = [ln[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "# # feed forward (inference) and get the network output\n",
    "# # measure how much it took in seconds\n",
    "# start = time.perf_counter()\n",
    "# layer_outputs = net.forward(ln)\n",
    "# time_took = time.perf_counter() - start\n",
    "# print(f\"Time took: {time_took:.2f}s\")\n",
    "\n",
    "# boxes, confidences, class_ids = [], [], []\n",
    "\n",
    "# # loop over each of the layer outputs\n",
    "# for output in layer_outputs:\n",
    "#     # loop over each of the object detections\n",
    "#     for detection in output:\n",
    "#         # extract the class id (label) and confidence (as a probability) of\n",
    "#         # the current object detection\n",
    "#         scores = detection[5:]\n",
    "#         class_id = np.argmax(scores)\n",
    "#         confidence = scores[class_id]\n",
    "#         # discard weak predictions by ensuring the detected\n",
    "#         # probability is greater than the minimum probability\n",
    "#         if confidence > CONFIDENCE:\n",
    "#             # scale the bounding box coordinates back relative to the\n",
    "#             # size of the image, keeping in mind that YOLO actually\n",
    "#             # returns the center (x, y)-coordinates of the bounding\n",
    "#             # box followed by the boxes' width and height\n",
    "#             box = detection[:4] * np.array([w, h, w, h])\n",
    "#             (centerX, centerY, width, height) = box.astype(\"int\")\n",
    "\n",
    "#             # use the center (x, y)-coordinates to derive the top and\n",
    "#             # and left corner of the bounding box\n",
    "#             x = int(centerX - (width / 2))\n",
    "#             y = int(centerY - (height / 2))\n",
    "\n",
    "#             # update our list of bounding box coordinates, confidences,\n",
    "#             # and class IDs\n",
    "#             boxes.append([x, y, int(width), int(height)])\n",
    "#             confidences.append(float(confidence))\n",
    "#             class_ids.append(class_id)\n",
    "\n",
    "# # perform the non maximum suppression given the scores defined before\n",
    "# idxs = cv2.dnn.NMSBoxes(boxes, confidences, SCORE_THRESHOLD, IOU_THRESHOLD)\n",
    "\n",
    "# font_scale = 1\n",
    "# thickness = 1\n",
    "\n",
    "# # ensure at least one detection exists\n",
    "# if len(idxs) > 0:\n",
    "#     # loop over the indexes we are keeping\n",
    "#     for i in idxs.flatten():\n",
    "#         # extract the bounding box coordinates\n",
    "#         x, y = boxes[i][0], boxes[i][1]\n",
    "#         w, h = boxes[i][2], boxes[i][3]\n",
    "#         # draw a bounding box rectangle and label on the image\n",
    "#         color = [int(c) for c in colors[class_ids[i]]]\n",
    "#         cv2.rectangle(image, (x, y), (x + w, y + h), color=color, thickness=thickness)\n",
    "#         text = f\"{labels[class_ids[i]]}: {confidences[i]:.2f}\"\n",
    "#         # calculate text width & height to draw the transparent boxes as background of the text\n",
    "#         (text_width, text_height) = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, fontScale=font_scale, thickness=thickness)[0]\n",
    "#         text_offset_x = x\n",
    "#         text_offset_y = y - 5\n",
    "#         box_coords = ((text_offset_x, text_offset_y), (text_offset_x + text_width + 2, text_offset_y - text_height))\n",
    "#         overlay = image.copy()\n",
    "#         cv2.rectangle(overlay, box_coords[0], box_coords[1], color=color, thickness=cv2.FILLED)\n",
    "#         # add opacity (transparency to the box)\n",
    "#         image = cv2.addWeighted(overlay, 0.6, image, 0.4, 0)\n",
    "#         # now put the text (label: confidence %)\n",
    "#         cv2.putText(image, text, (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "#             fontScale=font_scale, color=(0, 0, 0), thickness=thickness)\n",
    "        \n",
    "\n",
    "# cv2.imshow(\"image\", image)\n",
    "# if cv2.waitKey(0) == ord(\"q\"):\n",
    "#     pass\n",
    "\n",
    "# cv2.imwrite(filename + \"_yolo3.\" + ext, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import numpy as np\n",
    "\n",
    "# import time\n",
    "# import sys\n",
    "\n",
    "# CONFIDENCE = 0.5\n",
    "# SCORE_THRESHOLD = 0.5\n",
    "# IOU_THRESHOLD = 0.5\n",
    "# config_path = \"yolov3.cfg\"\n",
    "# weights_path = \"yolov3.weights\"\n",
    "# font_scale = 0.2\n",
    "# thickness = 0.1\n",
    "# labels = open(\"coco.names\").read().strip().split(\"\\n\")\n",
    "# colors = np.random.randint(0, 255, size=(len(labels), 3), dtype=\"uint8\")\n",
    "\n",
    "# net = cv2.dnn.readNetFromDarknet(config_path, weights_path)\n",
    "\n",
    "# ln = net.getLayerNames()\n",
    "# ln = [ln[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "# # read the file from the command line\n",
    "# video_file = 'video.mp4'\n",
    "# cap = cv2.VideoCapture(video_file)\n",
    "# _, image = cap.read()\n",
    "# h, w = image.shape[:2]\n",
    "# fourcc = cv2.VideoWriter_fourcc(*\"XVID\")\n",
    "# out = cv2.VideoWriter(\"output.avi\", fourcc, 20.0, (w, h))\n",
    "# while True:\n",
    "#     _, image = cap.read()\n",
    "\n",
    "#     h, w = image.shape[:2]\n",
    "#     blob = cv2.dnn.blobFromImage(image, 1/255.0, (416, 416), swapRB=True, crop=False)\n",
    "#     net.setInput(blob)\n",
    "#     start = time.perf_counter()\n",
    "#     layer_outputs = net.forward(ln)\n",
    "#     time_took = time.perf_counter() - start\n",
    "#     print(\"Time took:\", time_took)\n",
    "#     boxes, confidences, class_ids = [], [], []\n",
    "\n",
    "#     # loop over each of the layer outputs\n",
    "#     for output in layer_outputs:\n",
    "#         # loop over each of the object detections\n",
    "#         for detection in output:\n",
    "#             # extract the class id (label) and confidence (as a probability) of\n",
    "#             # the current object detection\n",
    "#             scores = detection[5:]\n",
    "#             class_id = np.argmax(scores)\n",
    "#             confidence = scores[class_id]\n",
    "#             # discard weak predictions by ensuring the detected\n",
    "#             # probability is greater than the minimum probability\n",
    "#             if confidence > CONFIDENCE:\n",
    "#                 # scale the bounding box coordinates back relative to the\n",
    "#                 # size of the image, keeping in mind that YOLO actually\n",
    "#                 # returns the center (x, y)-coordinates of the bounding\n",
    "#                 # box followed by the boxes' width and height\n",
    "#                 box = detection[:4] * np.array([w, h, w, h])\n",
    "#                 (centerX, centerY, width, height) = box.astype(\"int\")\n",
    "\n",
    "#                 # use the center (x, y)-coordinates to derive the top and\n",
    "#                 # and left corner of the bounding box\n",
    "#                 x = int(centerX - (width / 2))\n",
    "#                 y = int(centerY - (height / 2))\n",
    "\n",
    "#                 # update our list of bounding box coordinates, confidences,\n",
    "#                 # and class IDs\n",
    "#                 boxes.append([x, y, int(width), int(height)])\n",
    "#                 confidences.append(float(confidence))\n",
    "#                 class_ids.append(class_id)\n",
    "\n",
    "#     # perform the non maximum suppression given the scores defined before\n",
    "#     idxs = cv2.dnn.NMSBoxes(boxes, confidences, SCORE_THRESHOLD, IOU_THRESHOLD)\n",
    "\n",
    "#     font_scale = 1\n",
    "#     thickness = 1\n",
    "\n",
    "#     # ensure at least one detection exists\n",
    "#     if len(idxs) > 0:\n",
    "#         # loop over the indexes we are keeping\n",
    "#         for i in idxs.flatten():\n",
    "#             # extract the bounding box coordinates\n",
    "#             x, y = boxes[i][0], boxes[i][1]\n",
    "#             w, h = boxes[i][2], boxes[i][3]\n",
    "#             # draw a bounding box rectangle and label on the image\n",
    "#             color = [int(c) for c in colors[class_ids[i]]]\n",
    "#             cv2.rectangle(image, (x, y), (x + w, y + h), color=color, thickness=thickness)\n",
    "#             text = f\"{labels[class_ids[i]]}: {confidences[i]:.2f}\"\n",
    "#             # calculate text width & height to draw the transparent boxes as background of the text\n",
    "#             (text_width, text_height) = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, fontScale=font_scale, thickness=thickness)[0]\n",
    "#             text_offset_x = x\n",
    "#             text_offset_y = y - 5\n",
    "#             box_coords = ((text_offset_x, text_offset_y), (text_offset_x + text_width + 2, text_offset_y - text_height))\n",
    "#             overlay = image.copy()\n",
    "#             cv2.rectangle(overlay, box_coords[0], box_coords[1], color=color, thickness=cv2.FILLED)\n",
    "#             # add opacity (transparency to the box)\n",
    "#             image = cv2.addWeighted(overlay, 0.6, image, 0.4, 0)\n",
    "#             # now put the text (label: confidence %)\n",
    "#             cv2.putText(image, text, (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "#                 fontScale=font_scale, color=(0, 0, 0), thickness=thickness)\n",
    "\n",
    "#     out.write(image)\n",
    "#     cv2.imshow(\"image\", image)\n",
    "    \n",
    "#     if ord(\"q\") == cv2.waitKey(1):\n",
    "#         break\n",
    "\n",
    "\n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "truck:0.6418\ntruck:0.5168\ncar:0.5559\ncar:0.8305\ncar:0.9031\nperson:0.7672\ncar:0.8982\ncar:0.6754\ncar:0.9257\ncar:0.9496\ncar:0.7692\nperson:0.5067\ntruck:0.6057\ntruck:0.5186\ncar:0.5884\ncar:0.8796\ncar:0.8542\nperson:0.6382\ncar:0.9459\ncar:0.7441\ncar:0.9254\ncar:0.8822\ncar:0.8152\ntruck:0.7268\ncar:0.5280\ncar:0.7850\ncar:0.8136\ncar:0.9016\ncar:0.8262\ncar:0.7049\ncar:0.9300\ncar:0.9341\nperson:0.6522\ntruck:0.7043\ntruck:0.5462\ncar:0.7719\ncar:0.6626\ncar:0.9638\ncar:0.7998\ncar:0.9030\ncar:0.6813\ncar:0.9424\nperson:0.7870\ntruck:0.5467\ncar:0.5713\ntruck:0.8155\ncar:0.7190\ncar:0.6759\nperson:0.5933\ncar:0.8749\ncar:0.8463\ncar:0.8794\nperson:0.5054\ncar:0.5639\ncar:0.9573\nperson:0.8175\ntruck:0.5561\ntruck:0.6351\ncar:0.8869\ncar:0.8367\ncar:0.9435\ncar:0.7786\ncar:0.8729\nperson:0.6807\ncar:0.7291\ncar:0.8998\nperson:0.6508\n"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "labels_path = 'coco.names'\n",
    "labels = open(labels_path).read().split(\"\\n\")\n",
    "\n",
    "#define confidence level and threshold\n",
    "pre_conf = 0.5\n",
    "threshold = 0.3\n",
    "\n",
    "#Define different random colors for boxes\n",
    "np.random.seed(0)\n",
    "colors = np.random.randint(0,255,size=(len(labels),3),dtype='uint8')\n",
    "\n",
    "#path for YOLO_wightss and config file\n",
    "weights_path = 'yolov3.weights'\n",
    "config_path = 'yolov3.cfg'\n",
    "\n",
    "#Define neural net\n",
    "net = cv2.dnn.readNetFromDarknet(config_path,weights_path)\n",
    "ln = net.getLayerNames()\n",
    "\n",
    "ln =[ln[i[0]-1] for i in net.getUnconnectedOutLayers()]\n",
    "camera = cv2.VideoCapture(\"video.mp4\")\n",
    "cv2.namedWindow('name',cv2.WINDOW_NORMAL)\n",
    "while True:\n",
    "    ret,img = camera.read()    \n",
    "    #read image for detect objects and find height,width\n",
    "    img = cv2.resize(img,(416,416))\n",
    "    (H,W) = img.shape[:2]\n",
    "    \n",
    "    #Find YOLO Output layers \n",
    "    #give image as input to neural network\n",
    "    blob = cv2.dnn.blobFromImage(img,1/255.0,(416,416),swapRB=True,crop=False)\n",
    "    net.setInput(blob)\n",
    "    out_lay = net.forward(ln)\n",
    "\n",
    "\n",
    "    \n",
    "           #Identify best prediction and draw bounding boxes\n",
    "    for output in out_lay:\n",
    "        \n",
    "        for detection in output:\n",
    "            scores = detection[5:]\n",
    "            classId = np.argmax(scores)\n",
    "            confidence = scores[classId]\n",
    "            if confidence>pre_conf:\n",
    "                box = detection[0:4]*np.array([W,H,W,H])\n",
    "                (cenX,cenY,w,h) = box.astype('int32')\n",
    "                \n",
    "                x = int(cenX-(w/2))\n",
    "                y = int(cenY-(h/2))\n",
    "                color = [int(c) for c in colors[classId]]\n",
    "                cv2.rectangle(img,(x,y),(x+w,y+h),color,2)\n",
    "                text = print(\"{}:{:.4f}\".format(labels[classId],confidence))\n",
    "                cv2.putText(img,text,(cenX,cenY),cv2.FONT_HERSHEY_DUPLEX,2,color,4)\n",
    "\n",
    "\n",
    "    \n",
    "        cv2.imshow(\"name\",cv2.resize(img,(500,500)))\n",
    "        k = cv2.waitKey(30) & 0xff\n",
    "        if k == 27:\n",
    "            break\n",
    "\n",
    "camera.close()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ]
}